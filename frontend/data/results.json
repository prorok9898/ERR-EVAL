{
  "generated_at": "2025-12-24T00:22:19.795898",
  "dataset_version": "canonical",
  "entries": [
    {
      "rank": 1,
      "model_id": "openai/gpt-4o",
      "model_name": "GPT-4o",
      "overall_score": 8.92,
      "percentile": 99.0,
      "track_scores": {
        "A": 9.2,
        "B": 8.5,
        "C": 9.0,
        "D": 8.8,
        "E": 9.1
      },
      "axis_scores": {
        "ambiguity_detection": 1.9,
        "hallucination_avoidance": 1.8,
        "localization_of_uncertainty": 1.7,
        "response_strategy": 1.9,
        "epistemic_tone": 1.8
      },
      "avg_latency": 450.5,
      "avg_cost": 0.015,
      "evaluated_at": "2025-12-23T20:00:00.000000"
    },
    {
      "rank": 2,
      "model_id": "anthropic/claude-3-opus",
      "model_name": "Claude 3.5 Opus",
      "overall_score": 8.85,
      "percentile": 95.0,
      "track_scores": {
        "A": 9.0,
        "B": 9.2,
        "C": 8.5,
        "D": 8.9,
        "E": 8.7
      },
      "axis_scores": {
        "ambiguity_detection": 1.85,
        "hallucination_avoidance": 1.9,
        "localization_of_uncertainty": 1.8,
        "response_strategy": 1.8,
        "epistemic_tone": 1.9
      },
      "avg_latency": 1200.0,
      "avg_cost": 0.03,
      "evaluated_at": "2025-12-23T20:05:00.000000"
    },
    {
      "rank": 3,
      "model_id": "mistral/mixtral-8x22b",
      "model_name": "Mixtral 8x22B",
      "overall_score": 7.8,
      "percentile": 78.0,
      "track_scores": {
        "A": 8.0,
        "B": 7.5,
        "C": 7.9,
        "D": 7.6,
        "E": 8.0
      },
      "axis_scores": {
        "ambiguity_detection": 1.6,
        "hallucination_avoidance": 1.5,
        "localization_of_uncertainty": 1.5,
        "response_strategy": 1.6,
        "epistemic_tone": 1.6
      },
      "avg_latency": 600.0,
      "avg_cost": 0.008,
      "evaluated_at": "2025-12-23T20:20:00.000000"
    },
    {
      "rank": 4,
      "model_id": "google/gemini-pro-1.5",
      "model_name": "Gemini 1.5 Pro",
      "overall_score": 7.5,
      "percentile": 70.0,
      "track_scores": {
        "A": 7.0,
        "B": 7.8,
        "C": 7.2,
        "D": 7.5,
        "E": 8.0
      },
      "axis_scores": {
        "ambiguity_detection": 1.5,
        "hallucination_avoidance": 1.4,
        "localization_of_uncertainty": 1.6,
        "response_strategy": 1.5,
        "epistemic_tone": 1.5
      },
      "avg_latency": 320.0,
      "avg_cost": 0.005,
      "evaluated_at": "2025-12-23T20:10:00.000000"
    },
    {
      "rank": 5,
      "model_id": "openai/gpt-5.2",
      "model_name": "openai/gpt-5.2",
      "overall_score": 6.4,
      "percentile": 50.0,
      "track_scores": {
        "A": 7.0,
        "B": 7.0,
        "C": 5.0,
        "D": 6.0,
        "E": 7.0
      },
      "axis_scores": {
        "ambiguity_detection": 1.2,
        "hallucination_avoidance": 1.4,
        "localization_of_uncertainty": 1.2,
        "response_strategy": 1.0,
        "epistemic_tone": 1.6
      },
      "avg_latency": 7565.4,
      "avg_cost": 0.012995,
      "evaluated_at": "2025-12-24T00:22:19.755015"
    },
    {
      "rank": 6,
      "model_id": "meta/llama-3-8b-instruct",
      "model_name": "Llama 3 8B",
      "overall_score": 5.2,
      "percentile": 40.0,
      "track_scores": {
        "A": 5.5,
        "B": 5.0,
        "C": 4.8,
        "D": 5.5,
        "E": 5.2
      },
      "axis_scores": {
        "ambiguity_detection": 1.0,
        "hallucination_avoidance": 1.1,
        "localization_of_uncertainty": 0.9,
        "response_strategy": 1.0,
        "epistemic_tone": 1.1
      },
      "avg_latency": 150.0,
      "avg_cost": 0.0002,
      "evaluated_at": "2025-12-23T20:15:00.000000"
    }
  ]
}